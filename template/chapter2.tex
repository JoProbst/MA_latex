\chapter{Related Work}\label{related-work}
The work presented in this thesis is based on two main areas of research: Evaluation of Large Language Models and Information Retrieval.
In this chapter, the current state of research in those areas is presented, as it relates to this thesis.
We start with a short introduction to Large Language Models, then present the current evaluation methods for those models.
\\
Afterwards, the field of Information Retrieval is introduced.
Different retrieval methods used in this thesis are presented, together with the evaluation metrics used to compare them.

\section{Evaluation methods for Large Language Models}\label{evaluation-of-large-language-models}
Language Models are usually defined as systems, that produce probability distributions over a set of tokens, given the preceding or surrounding context.
The rise of Large Language Models (LLMs), started with the introduction of the new Transformer architecture~(\cite{vaswani:2017}), followed by the release of models like BERT~(\cite{devlin:2018}) and GPT-2~(\cite{radford:2018}).
With the release of GPT-3~(\cite{brown:2020}), the size of datasets used to train LLMs, as well as the number of parameters in the models, increased to a point, where the models are able to produce coherent text on a wide range of tasks.


\section{Retrieval Models}\label{retrieval-models}
Information retrieval (IR) is the process of retrieving relevant information from a collection of documents.
Given a query, an IR system returns a ranked list of documents that are most relevant to the query.
To achieve this, IR systems estimate a usefulness score for each document in the collection with respect to the query.
The documents are then ranked according to their usefulness scores, with the most relevant documents appearing at the top of the list.



\subsection{Baseline Retrieval Models}\label{baseline-retrieval-models}
First, we will look at the basic retrieval models.
Those are often used as baselines and in most use cases offer a good tradeoff between performance and computational complexity.

\subsubsection{TF-IDF}\label{tf-idf}
\subsubsection{BM25}\label{bm25}
\subsubsection{DPH}\label{dph}

\subsection{Neural Retrieval Models}\label{neural-retrieval-models}

\section{Evaluation of Retrieval Models}\label{evaluation-of-retrieval-models}