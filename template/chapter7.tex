\chapter{Future Work and Conclusion}\label{conclusion}

\section{Future Work}
In this thesis we present a first approach of using IR methods for evaluating LLMs in LFQA, specifically in the medical domain.
However, there is substantial room for further research and development.
Some areas on which future work could focus are:

\begin{enumerate}
    \item \textbf{Dataset Improvements:} The currently used dataset is not originally designed for LFQA and has some limitations, as discussed in Chapter \ref{sec:scope-and-limitations}. Future work could focus on designing a more comprehensive dataset that addresses these limitations and provides a more challenging benchmark for LLMs. An intermediate step could be to use the existing dataset and incorporate more sophisticated preprocessing steps to improve the quality of the data. Redoing the current annotations using a more consistent methodology could also improve the dataset quality.
    \item \textbf{Retrieval Pipeline Improvements:} The retrieval pipeline used in this thesis is a first attempt at using IR methods for evaluating LLMs in LFQA. Future work could focus on improving the pipeline's performance and investigate closer in which cases the retrieval pipeline produces different rankings than the human annotators.
    \item \textbf{Multidimensional Evaluation:} The currently used retrieval pipeline is only trained to rank documents based on their relevance, which is only one of the dimensions of answer quality. Future work could focus on extending the pipeline to also rank documents based on their readability and credibility.
    \item \textbf{Professional Evaluation:} The used retrieval pipeline is evaluated on the human ranked documents from the dataset, but after including the LLM generated answers the produced ranking is not evaluated again by medical experts. Future work could evaluate if human experts prefer the highest ranked LLM generated answers over the highly ranked web answers.
    \item \textbf{Conversational LLMs:} As the current application of LLMs in chatbots is focusing on conversational experiences, it is important to already consider the evaluation of these systems, which is more complex than the evaluation of single answers. How could the proposed retrieval-based implicit evaluation be extended to evaluate conversational LLMs?
\end{enumerate}

\section{Conclusion}
In conclusion, this thesis has introduced a new approach to evaluating LLMs for LFQA tasks using a retrieval-based implicit evaluation method. Our findings, as discussed in Chapter \ref{chapter:results} and Chapter \ref{discussion}, highlight the various factors that influence the effectiveness of LLMs in this context.

The proposed method has shown promise in reducing the reliance on human evaluations, thereby potentially lowering the costs and increasing the consistency in evaluating LLMs. However, as outlined in Chapter \ref{sec:scope-and-limitations}, this approach is not without limitations and should be considered a starting point for future research.

The rapid development and widespread adoption of LLMs, especially in applications like ChatGPT, as mentioned in Chapter \ref{structure}, underscore the importance of robust and scalable evaluation methods. The healthcare domain, in particular, presents unique challenges and opportunities for the application of LLMs. It is crucial that we continue to refine our evaluation methodologies to ensure that these powerful tools are used effectively and responsibly.

This thesis represents a step forward in the ongoing journey to understand and harness the potential of LLMs in answering complex, open-ended questions, particularly in sensitive domains like healthcare. The path ahead is filled with exciting possibilities and challenges, and it is hoped that this work will inspire and inform future endeavors in this dynamic field.

