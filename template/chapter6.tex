
\chapter{Limitations}\label{limitations}


\section{Dataset Properties and Challenges}

The properties and challenges of our dataset are crucial in understanding the context and limitations of our results:

\begin{enumerate}
    \item \textbf{Size and Scope:} The dataset is confined in size and scope, focusing solely on health-related questions. This limits its generalizability across different domains and question types.
    \item \textbf{Data Quality:} Since the dataset is derived from web content, it includes noise introduced during preprocessing. This noise potentially impacts the quality and reliability of the benchmarks.
    \item \textbf{Subjectivity in Annotations:} The annotations' subjective nature leads to inconsistencies, especially when involving multiple raters. This subjectivity can skew the evaluation of LLMs' responses.
    \item \textbf{Relevance of Query Types:} The dataset's reliance on question-type queries, as opposed to keyword-based queries, might limit the applicability of our findings. This suggests an area for future improvement in dataset design for LFQA systems.
\end{enumerate}

\section{Retrieval Pipeline Limitations}

The limitations of our retrieval pipeline are important to acknowledge as they influence the interpretation of our results:

\begin{enumerate}
    \item \textbf{Performance Gains:} There is a lack of significant performance improvement in transformer models over the baseline, and the impact of Query Expansion (QE) is minimal.
    \item \textbf{Relevance and Readability:} Our pipeline showed the best performance in terms of readability, rather than relevance. This outcome may be due to transformer models considering the full text of documents, including structural elements that influence readability.
    \item \textbf{Credibility Assessment:} The pipeline's credibility assessment was the weakest, likely because it lacks specific mechanisms to judge this quality dimension.
    \item \textbf{Role of Transformer Models:} Transformer models like monoT5, which diverge from traditional retrieval methods like indexing or direct document comparison, challenge the conventional understanding of retrieval models.
    \item \textbf{Efficiency vs Effectiveness:} Our research focused exclusively on the effectiveness of the retrieval process, not considering the efficiency aspect, which is vital in real-world applications.
\end{enumerate}

These limitations underscore the complexity of designing effective and reliable retrieval pipelines for evaluating LLMs in the context of long-form question answering.


